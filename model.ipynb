{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21b3cf1",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "df36df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "dfs = [\n",
    "    pd.read_csv(\"data/2024-12-31/prices.csv\", parse_dates=[\"date\"]),\n",
    "    pd.read_csv(\"data/2024-12-31/cash_rate.csv\", parse_dates=[\"date\"]), #prev\n",
    "    pd.read_csv(\"data/2024-12-31/signals.csv\", parse_dates=[\"date\"]),\n",
    "    pd.read_csv(\"data/2024-12-31/volumes.csv\", parse_dates=[\"date\"])\n",
    "    ]\n",
    "\n",
    "df = (\n",
    "    reduce(\n",
    "        lambda left, right: pd.merge(left, right, on=\"date\", how=\"left\"),\n",
    "        dfs\n",
    "    )\n",
    "    .sort_values(\"date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def add_periodic_date_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    date = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    day_of_week = date.dt.dayofweek\n",
    "    day_of_year = date.dt.dayofyear\n",
    "    month = date.dt.month\n",
    "    week_of_year = date.dt.isocalendar().week.astype(int)\n",
    "\n",
    "    df[\"dow_sin\"] = np.sin(2 * np.pi * day_of_week / 7)\n",
    "    df[\"dow_cos\"] = np.cos(2 * np.pi * day_of_week / 7)\n",
    "    df[\"doy_sin\"] = np.sin(2 * np.pi * day_of_year / 365.25)\n",
    "    df[\"doy_cos\"] = np.cos(2 * np.pi * day_of_year / 365.25)\n",
    "    df[\"month_sin\"] = np.sin(2 * np.pi * month / 12)\n",
    "    df[\"month_cos\"] = np.cos(2 * np.pi * month / 12)\n",
    "    df[\"woy_sin\"] = np.sin(2 * np.pi * week_of_year / 52.18)\n",
    "    df[\"woy_cos\"] = np.cos(2 * np.pi * week_of_year / 52.18)\n",
    "    return df\n",
    "\n",
    "df = add_periodic_date_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f6d0a05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2851\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2851 entries, 0 to 2850\n",
      "Data columns (total 83 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   date                   2851 non-null   datetime64[ns]\n",
      " 1   INSTRUMENT_1           2851 non-null   float64       \n",
      " 2   INSTRUMENT_2           2851 non-null   float64       \n",
      " 3   INSTRUMENT_3           2851 non-null   float64       \n",
      " 4   INSTRUMENT_4           2851 non-null   float64       \n",
      " 5   INSTRUMENT_5           2851 non-null   float64       \n",
      " 6   INSTRUMENT_6           2851 non-null   float64       \n",
      " 7   INSTRUMENT_7           2851 non-null   float64       \n",
      " 8   INSTRUMENT_8           2851 non-null   float64       \n",
      " 9   INSTRUMENT_9           2851 non-null   float64       \n",
      " 10  INSTRUMENT_10          2851 non-null   float64       \n",
      " 11  1mo                    2000 non-null   float64       \n",
      " 12  1.5month               0 non-null      float64       \n",
      " 13  2mo                    1552 non-null   float64       \n",
      " 14  3mo                    2000 non-null   float64       \n",
      " 15  4mo                    550 non-null    float64       \n",
      " 16  6mo                    2000 non-null   float64       \n",
      " 17  1yr                    2000 non-null   float64       \n",
      " 18  2yr                    2000 non-null   float64       \n",
      " 19  3yr                    2000 non-null   float64       \n",
      " 20  5yr                    2000 non-null   float64       \n",
      " 21  7yr                    2000 non-null   float64       \n",
      " 22  10yr                   2000 non-null   float64       \n",
      " 23  20yr                   2000 non-null   float64       \n",
      " 24  30yr                   2000 non-null   float64       \n",
      " 25  INSTRUMENT_1_trend4    2835 non-null   float64       \n",
      " 26  INSTRUMENT_1_trend8    2819 non-null   float64       \n",
      " 27  INSTRUMENT_1_trend16   2787 non-null   float64       \n",
      " 28  INSTRUMENT_1_trend32   2723 non-null   float64       \n",
      " 29  INSTRUMENT_2_trend4    2835 non-null   float64       \n",
      " 30  INSTRUMENT_2_trend8    2819 non-null   float64       \n",
      " 31  INSTRUMENT_2_trend16   2787 non-null   float64       \n",
      " 32  INSTRUMENT_2_trend32   2723 non-null   float64       \n",
      " 33  INSTRUMENT_3_trend4    2835 non-null   float64       \n",
      " 34  INSTRUMENT_3_trend8    2819 non-null   float64       \n",
      " 35  INSTRUMENT_3_trend16   2787 non-null   float64       \n",
      " 36  INSTRUMENT_3_trend32   2723 non-null   float64       \n",
      " 37  INSTRUMENT_4_trend4    2835 non-null   float64       \n",
      " 38  INSTRUMENT_4_trend8    2819 non-null   float64       \n",
      " 39  INSTRUMENT_4_trend16   2787 non-null   float64       \n",
      " 40  INSTRUMENT_4_trend32   2723 non-null   float64       \n",
      " 41  INSTRUMENT_5_trend4    2835 non-null   float64       \n",
      " 42  INSTRUMENT_5_trend8    2819 non-null   float64       \n",
      " 43  INSTRUMENT_5_trend16   2787 non-null   float64       \n",
      " 44  INSTRUMENT_5_trend32   2723 non-null   float64       \n",
      " 45  INSTRUMENT_6_trend4    2835 non-null   float64       \n",
      " 46  INSTRUMENT_6_trend8    2819 non-null   float64       \n",
      " 47  INSTRUMENT_6_trend16   2787 non-null   float64       \n",
      " 48  INSTRUMENT_6_trend32   2723 non-null   float64       \n",
      " 49  INSTRUMENT_7_trend4    2835 non-null   float64       \n",
      " 50  INSTRUMENT_7_trend8    2819 non-null   float64       \n",
      " 51  INSTRUMENT_7_trend16   2787 non-null   float64       \n",
      " 52  INSTRUMENT_7_trend32   2723 non-null   float64       \n",
      " 53  INSTRUMENT_8_trend4    2835 non-null   float64       \n",
      " 54  INSTRUMENT_8_trend8    2819 non-null   float64       \n",
      " 55  INSTRUMENT_8_trend16   2787 non-null   float64       \n",
      " 56  INSTRUMENT_8_trend32   2723 non-null   float64       \n",
      " 57  INSTRUMENT_9_trend4    2835 non-null   float64       \n",
      " 58  INSTRUMENT_9_trend8    2819 non-null   float64       \n",
      " 59  INSTRUMENT_9_trend16   2787 non-null   float64       \n",
      " 60  INSTRUMENT_9_trend32   2723 non-null   float64       \n",
      " 61  INSTRUMENT_10_trend4   2835 non-null   float64       \n",
      " 62  INSTRUMENT_10_trend8   2819 non-null   float64       \n",
      " 63  INSTRUMENT_10_trend16  2787 non-null   float64       \n",
      " 64  INSTRUMENT_10_trend32  2723 non-null   float64       \n",
      " 65  INSTRUMENT_1_vol       2851 non-null   int64         \n",
      " 66  INSTRUMENT_2_vol       2851 non-null   int64         \n",
      " 67  INSTRUMENT_3_vol       2851 non-null   int64         \n",
      " 68  INSTRUMENT_4_vol       2851 non-null   int64         \n",
      " 69  INSTRUMENT_5_vol       2851 non-null   int64         \n",
      " 70  INSTRUMENT_6_vol       2851 non-null   int64         \n",
      " 71  INSTRUMENT_7_vol       2851 non-null   int64         \n",
      " 72  INSTRUMENT_8_vol       2851 non-null   int64         \n",
      " 73  INSTRUMENT_9_vol       2851 non-null   int64         \n",
      " 74  INSTRUMENT_10_vol      2851 non-null   int64         \n",
      " 75  dow_sin                2851 non-null   float64       \n",
      " 76  dow_cos                2851 non-null   float64       \n",
      " 77  doy_sin                2851 non-null   float64       \n",
      " 78  doy_cos                2851 non-null   float64       \n",
      " 79  month_sin              2851 non-null   float64       \n",
      " 80  month_cos              2851 non-null   float64       \n",
      " 81  woy_sin                2851 non-null   float64       \n",
      " 82  woy_cos                2851 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(72), int64(10)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bb8f4b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUMENTS = [f\"INSTRUMENT_{i}\" for i in range(1, 11)]\n",
    "DATE_FEATURES = [\n",
    "    \"dow_sin\", \"dow_cos\",\n",
    "    \"doy_sin\", \"doy_cos\",\n",
    "    \"month_sin\", \"month_cos\",\n",
    "    \"woy_sin\", \"woy_cos\",\n",
    "]\n",
    "MACRO_FEATURES = [\n",
    "    c for c in [\"1mo\", \"1.5month\", \"2mo\", \"3mo\", \"4mo\", \"6mo\",\n",
    "                \"1yr\", \"2yr\", \"3yr\", \"5yr\", \"7yr\", \"10yr\", \"20yr\", \"30yr\"]\n",
    "    if c in df.columns and df[c].notna().mean() > 0.5\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4eaa872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray):\n",
    "    x = x - np.max(x)  # stability\n",
    "    e = np.exp(x)\n",
    "    return e / (e.sum() + 1e-12)\n",
    "\n",
    "def cap_and_renorm(w: pd.Series, cap=0.25) -> pd.Series:\n",
    "    w = w.clip(lower=0.0, upper=cap)\n",
    "    s = float(w.sum())\n",
    "    if s <= 0:\n",
    "        return pd.Series(1.0 / len(w), index=w.index)\n",
    "    return w / s\n",
    "\n",
    "def build_feature_cols(df: pd.DataFrame):\n",
    "    return [col for col in df.columns if col != \"date\"]\n",
    "\n",
    "def make_labels_next_return(df: pd.DataFrame, inst: str):\n",
    "    x = df[inst].astype(float)\n",
    "    return x.shift(-1) / x - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fbcc90d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results by instrument:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_val</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>val_corr</th>\n",
       "      <th>val_hit_rate</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INSTRUMENT_8</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INSTRUMENT_10</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INSTRUMENT_9</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.5397</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INSTRUMENT_5</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INSTRUMENT_7</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INSTRUMENT_1</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.4881</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INSTRUMENT_4</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSTRUMENT_2</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INSTRUMENT_6</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INSTRUMENT_3</td>\n",
       "      <td>2598</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      instrument  n_train  n_val  val_rmse  val_corr  val_hit_rate  \\\n",
       "7   INSTRUMENT_8     2598    252    0.0147    0.1432        0.5833   \n",
       "9  INSTRUMENT_10     2598    252    0.0338    0.1358        0.5516   \n",
       "8   INSTRUMENT_9     2598    252    0.0258    0.1254        0.5397   \n",
       "4   INSTRUMENT_5     2598    252    0.0075    0.0460        0.5516   \n",
       "6   INSTRUMENT_7     2598    252    0.0096    0.0342        0.5516   \n",
       "0   INSTRUMENT_1     2598    252    0.0077    0.0255        0.4881   \n",
       "3   INSTRUMENT_4     2598    252    0.0092    0.0204        0.5635   \n",
       "1   INSTRUMENT_2     2598    252    0.0104    0.0118        0.5000   \n",
       "5   INSTRUMENT_6     2598    252    0.0035    0.0115        0.5317   \n",
       "2   INSTRUMENT_3     2598    252    0.0077    0.0024        0.5317   \n",
       "\n",
       "                                         best_params  \n",
       "7  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "9  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "8  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "4  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "6  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "0  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "3  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "1  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "5  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  \n",
       "2  {'colsample_bytree': 0.8, 'learning_rate': 0.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average validation metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>val_corr</th>\n",
       "      <th>val_hit_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.5393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      val_rmse  val_corr  val_hit_rate\n",
       "mean     0.013    0.0556        0.5393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def train_predict_scores(\n",
    "    df: pd.DataFrame,\n",
    "    min_train: int = 750,\n",
    "    val_size: int = 252,\n",
    "):\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    feat_cols = build_feature_cols(df)\n",
    "    X_all = df.iloc[:-1][feat_cols].copy()\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [150, 300],\n",
    "        \"max_depth\": [3, 4],\n",
    "        \"learning_rate\": [0.03, 0.05],\n",
    "        \"subsample\": [0.8],\n",
    "        \"colsample_bytree\": [0.8],\n",
    "        \"reg_lambda\": [1.0, 3.0],\n",
    "    }\n",
    "\n",
    "    preds = {}\n",
    "    validation_rows = []\n",
    "\n",
    "    for inst in INSTRUMENTS:\n",
    "        y_all = make_labels_next_return(df, inst).iloc[:-1]\n",
    "        mask = ~y_all.isna()\n",
    "\n",
    "        X = X_all.loc[mask]\n",
    "        y = y_all.loc[mask]\n",
    "\n",
    "        if len(X) < min_train + val_size:\n",
    "            preds[inst] = 0.0\n",
    "            validation_rows.append(\n",
    "                {\n",
    "                    \"instrument\": inst,\n",
    "                    \"n_train\": 0,\n",
    "                    \"n_val\": 0,\n",
    "                    \"best_params\": None,\n",
    "                    \"val_rmse\": np.nan,\n",
    "                    \"val_corr\": np.nan,\n",
    "                    \"val_hit_rate\": np.nan,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        X_train = X.iloc[:-val_size]\n",
    "        y_train = y.iloc[:-val_size]\n",
    "        X_val = X.iloc[-val_size:]\n",
    "        y_val = y.iloc[-val_size:]\n",
    "\n",
    "        best_model = None\n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "\n",
    "        for params in ParameterGrid(param_grid):\n",
    "            model = XGBRegressor(\n",
    "                objective=\"reg:squarederror\",\n",
    "                tree_method=\"hist\",\n",
    "                random_state=0,\n",
    "                n_jobs=1,\n",
    "                **params,\n",
    "            )\n",
    "            model.fit(X_train.values, y_train.values)\n",
    "\n",
    "            val_pred = model.predict(X_val.values)\n",
    "            val_corr = pd.Series(val_pred).corr(pd.Series(y_val.values))\n",
    "            val_corr = 0.0 if pd.isna(val_corr) else float(val_corr)\n",
    "\n",
    "            if val_corr > best_score:\n",
    "                best_score = val_corr\n",
    "                best_model = model\n",
    "                best_params = params\n",
    "\n",
    "        val_pred = best_model.predict(X_val.values)\n",
    "        val_rmse = float(np.sqrt(np.mean((val_pred - y_val.values) ** 2)))\n",
    "        val_corr = pd.Series(val_pred).corr(pd.Series(y_val.values))\n",
    "        val_corr = 0.0 if pd.isna(val_corr) else float(val_corr)\n",
    "        val_hit_rate = float(((val_pred > 0) == (y_val.values > 0)).mean())\n",
    "\n",
    "        validation_rows.append(\n",
    "            {\n",
    "                \"instrument\": inst,\n",
    "                \"n_train\": len(X_train),\n",
    "                \"n_val\": len(X_val),\n",
    "                \"best_params\": best_params,\n",
    "                \"val_rmse\": val_rmse,\n",
    "                \"val_corr\": val_corr,\n",
    "                \"val_hit_rate\": val_hit_rate,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Refit on all available history with the best hyperparameters\n",
    "        final_model = XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=0,\n",
    "            n_jobs=1,\n",
    "            **best_params,\n",
    "        )\n",
    "        final_model.fit(X.values, y.values)\n",
    "\n",
    "        x_last = df.loc[df.index[-1], feat_cols].astype(float)\n",
    "        preds[inst] = float(final_model.predict([x_last.values])[0])\n",
    "\n",
    "    validation_df = pd.DataFrame(validation_rows).sort_values(\"val_corr\", ascending=False)\n",
    "\n",
    "    print(\"Validation results by instrument:\")\n",
    "    display(\n",
    "        validation_df[\n",
    "            [\"instrument\", \"n_train\", \"n_val\", \"val_rmse\", \"val_corr\", \"val_hit_rate\", \"best_params\"]\n",
    "        ].round(4)\n",
    "    )\n",
    "\n",
    "    print(\"\\nAverage validation metrics:\")\n",
    "    display(\n",
    "        validation_df[[\"val_rmse\", \"val_corr\", \"val_hit_rate\"]].mean().to_frame(\"mean\").T.round(4)\n",
    "    )\n",
    "\n",
    "    return model, pd.Series(preds)\n",
    "\n",
    "model, pred = train_predict_scores(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "21cd5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_weights(pred: pd.Series,\n",
    "                      beta=5.0,\n",
    "                      cap=0.25,\n",
    "                      smooth_alpha=0.35,\n",
    "                      prev_weights: pd.Series | None = None):\n",
    "    \n",
    "\n",
    "    # Use predictions directly. Raw *_vol columns are traded volume, not return volatility.\n",
    "    scores = pred.copy()\n",
    "\n",
    "    w = pd.Series(softmax(beta * scores.values), index=INSTRUMENTS)\n",
    "    w = cap_and_renorm(w, cap=cap)\n",
    "\n",
    "    if prev_weights is not None:\n",
    "        prev_weights = prev_weights.reindex(INSTRUMENTS).fillna(0.0)\n",
    "        prev_weights = prev_weights / prev_weights.sum()\n",
    "        w = smooth_alpha * w + (1.0 - smooth_alpha) * prev_weights\n",
    "        w = cap_and_renorm(w, cap=cap)\n",
    "\n",
    "    return w\n",
    "\n",
    "def write_submission(weights: pd.Series, team_name: str, round_n: int, out_path=\".\"):\n",
    "    out = pd.DataFrame({\"asset\": weights.index, \"weight\": weights.values})\n",
    "    fname = f\"{team_name}_round_{round_n}.csv\"\n",
    "    out.to_csv(f\"{out_path}/{fname}\", index=False)\n",
    "    return fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e1534c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: HiddenLabel_round_1.csv\n",
      "INSTRUMENT_1     0.099252\n",
      "INSTRUMENT_2     0.097238\n",
      "INSTRUMENT_3     0.100249\n",
      "INSTRUMENT_4     0.099738\n",
      "INSTRUMENT_5     0.099608\n",
      "INSTRUMENT_6     0.099529\n",
      "INSTRUMENT_7     0.101037\n",
      "INSTRUMENT_8     0.100646\n",
      "INSTRUMENT_9     0.101023\n",
      "INSTRUMENT_10    0.101680\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# optional: load your last submitted weights for smoothing\n",
    "# prev = pd.read_csv(\"myteam_round_3.csv\").set_index(\"asset\")[\"weight\"]\n",
    "prev = None\n",
    "\n",
    "w = construct_weights(pred, prev_weights=prev)\n",
    "fname = write_submission(w, team_name=\"HiddenLabel\", round_n=1, out_path=\".\")\n",
    "print(\"Wrote:\", fname)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9eda64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backtest_model(\n",
    "#     df: pd.DataFrame,\n",
    "#     start_idx: int = 1500,\n",
    "#     retrain_every: int = 21,\n",
    "#     beta: float = 5.0,\n",
    "# ):\n",
    "#     feat_cols = build_feature_cols(df)\n",
    "#     next_returns = pd.DataFrame(\n",
    "#         {inst: df[inst].shift(-1) / df[inst] - 1.0 for inst in INSTRUMENTS}\n",
    "#     )\n",
    "\n",
    "#     pred_rows = []\n",
    "\n",
    "#     for t in range(start_idx, len(df) - 1, retrain_every):\n",
    "#         X_train_full = df.iloc[:t][feat_cols]\n",
    "#         x_test = df.loc[t, feat_cols].astype(float)\n",
    "\n",
    "#         row = {\"date\": df.loc[t, \"date\"]}\n",
    "\n",
    "#         for inst in INSTRUMENTS:\n",
    "#             y_train_full = next_returns[inst].iloc[:t]\n",
    "#             mask = ~y_train_full.isna()\n",
    "\n",
    "#             X_train = X_train_full.loc[mask]\n",
    "#             y_train = y_train_full.loc[mask]\n",
    "\n",
    "#             if len(X_train) < 200:\n",
    "#                 row[inst] = np.nan\n",
    "#                 continue\n",
    "\n",
    "#             model = XGBRegressor(\n",
    "#                 n_estimators=300,\n",
    "#                 max_depth=4,\n",
    "#                 learning_rate=0.05,\n",
    "#                 subsample=0.8,\n",
    "#                 colsample_bytree=0.8,\n",
    "#                 reg_alpha=0.0,\n",
    "#                 reg_lambda=1.0,\n",
    "#                 objective=\"reg:squarederror\",\n",
    "#                 tree_method=\"hist\",\n",
    "#                 random_state=0,\n",
    "#                 n_jobs=1,\n",
    "#             )\n",
    "#             model.fit(X_train.values, y_train.values)\n",
    "#             row[inst] = float(model.predict([x_test.values])[0])\n",
    "\n",
    "#         pred_rows.append(row)\n",
    "\n",
    "#     pred_df = pd.DataFrame(pred_rows)\n",
    "\n",
    "#     actual_df = next_returns.iloc[start_idx : len(df) - 1 : retrain_every].reset_index(drop=True)\n",
    "#     actual_df.insert(\n",
    "#         0,\n",
    "#         \"date\",\n",
    "#         df[\"date\"].iloc[start_idx : len(df) - 1 : retrain_every].reset_index(drop=True),\n",
    "#     )\n",
    "\n",
    "#     pred_mat = pred_df[INSTRUMENTS]\n",
    "#     act_mat = actual_df[INSTRUMENTS]\n",
    "\n",
    "#     ic_by_date = pred_mat.corrwith(act_mat, axis=1, method=\"spearman\")\n",
    "#     directional_accuracy = ((pred_mat.values > 0) == (act_mat.values > 0)).mean()\n",
    "\n",
    "#     scores = pred_mat.to_numpy()\n",
    "#     scores = scores - np.nanmax(scores, axis=1, keepdims=True)\n",
    "#     exp_scores = np.exp(beta * scores)\n",
    "#     weights = exp_scores / np.nansum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "#     portfolio_returns = (weights * act_mat.to_numpy()).sum(axis=1)\n",
    "#     equity_curve = pd.Series((1 + portfolio_returns).cumprod(), index=pred_df[\"date\"])\n",
    "\n",
    "#     ann_factor = np.sqrt(252 / retrain_every)\n",
    "#     sharpe = portfolio_returns.mean() / (portfolio_returns.std(ddof=1) + 1e-12) * ann_factor\n",
    "\n",
    "#     running_max = equity_curve.cummax()\n",
    "#     drawdown = equity_curve / running_max - 1.0\n",
    "#     max_drawdown = drawdown.min()\n",
    "\n",
    "#     metrics = pd.Series(\n",
    "#         {\n",
    "#             \"n_test_points\": len(pred_df),\n",
    "#             \"mean_spearman_ic\": ic_by_date.mean(),\n",
    "#             \"hit_rate\": directional_accuracy,\n",
    "#             \"annualized_sharpe\": sharpe,\n",
    "#             \"avg_period_return\": portfolio_returns.mean(),\n",
    "#             \"vol_period_return\": portfolio_returns.std(ddof=1),\n",
    "#             \"total_return\": equity_curve.iloc[-1] - 1.0,\n",
    "#             \"max_drawdown\": max_drawdown,\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     results = {\n",
    "#         \"predictions\": pred_df,\n",
    "#         \"actuals\": actual_df,\n",
    "#         \"ic_by_date\": ic_by_date,\n",
    "#         \"portfolio_returns\": pd.Series(portfolio_returns, index=pred_df[\"date\"]),\n",
    "#         \"equity_curve\": equity_curve,\n",
    "#         \"metrics\": metrics,\n",
    "#     }\n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e5793fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bt = backtest_model(df, start_idx=1500, retrain_every=21, beta=5.0)\n",
    "\n",
    "# print(bt[\"metrics\"].round(4))\n",
    "\n",
    "# bt[\"equity_curve\"].plot(title=\"Out-of-Sample Equity Curve\", figsize=(10, 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
