{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"2025-02-28\"\n",
    "\n",
    "df_prices = pd.read_csv(f\"data/{DATE}/prices.csv\", parse_dates=[\"date\"])\n",
    "df_cash_rates = pd.read_csv(f\"data/{DATE}/cash_rate.csv\", parse_dates=[\"date\"])\n",
    "df_signals = pd.read_csv(f\"data/{DATE}/signals.csv\", parse_dates=[\"date\"])\n",
    "df_volumes = pd.read_csv(f\"data/{DATE}/volumes.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "dfs = [df_prices, df_cash_rates, df_signals, df_volumes]\n",
    "\n",
    "df = (\n",
    "    reduce(\n",
    "        lambda left, right: pd.merge(left, right, on=\"date\", how=\"left\"),\n",
    "        dfs,\n",
    "    )\n",
    "    .sort_values(\"date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def add_periodic_date_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    date = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    day_of_week = date.dt.dayofweek\n",
    "    day_of_year = date.dt.dayofyear\n",
    "    month = date.dt.month\n",
    "    week_of_year = date.dt.isocalendar().week.astype(int)\n",
    "\n",
    "    df[\"dow_sin\"] = np.sin(2 * np.pi * day_of_week / 7)\n",
    "    df[\"dow_cos\"] = np.cos(2 * np.pi * day_of_week / 7)\n",
    "    df[\"doy_sin\"] = np.sin(2 * np.pi * day_of_year / 365.25)\n",
    "    df[\"doy_cos\"] = np.cos(2 * np.pi * day_of_year / 365.25)\n",
    "    df[\"month_sin\"] = np.sin(2 * np.pi * month / 12)\n",
    "    df[\"month_cos\"] = np.cos(2 * np.pi * month / 12)\n",
    "    df[\"woy_sin\"] = np.sin(2 * np.pi * week_of_year / 52.18)\n",
    "    df[\"woy_cos\"] = np.cos(2 * np.pi * week_of_year / 52.18)\n",
    "    return df\n",
    "\n",
    "def add_instrument_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    for inst in [f\"INSTRUMENT_{i}\" for i in range(1, 11)]:\n",
    "        px = df[inst].astype(float)\n",
    "        ret_1 = px.pct_change()\n",
    "        log_ret_1 = np.log(px).diff()\n",
    "\n",
    "        df[f\"{inst}_ret1\"] = ret_1\n",
    "        df[f\"{inst}_logret1\"] = log_ret_1\n",
    "        df[f\"{inst}_mom5\"] = px.pct_change(5)\n",
    "        df[f\"{inst}_mom20\"] = px.pct_change(20)\n",
    "        df[f\"{inst}_mom60\"] = px.pct_change(60)\n",
    "        df[f\"{inst}_vol20\"] = ret_1.rolling(20).std()\n",
    "        df[f\"{inst}_vol60\"] = ret_1.rolling(60).std()\n",
    "        df[f\"{inst}_ma_ratio20\"] = px / px.rolling(20).mean() - 1.0\n",
    "        df[f\"{inst}_ma_ratio60\"] = px / px.rolling(60).mean() - 1.0\n",
    "\n",
    "        vol_col = f\"{inst}_vol\"\n",
    "        if vol_col in df.columns:\n",
    "            log_vol = np.log1p(df[vol_col].astype(float))\n",
    "            df[f\"{inst}_logvol\"] = log_vol\n",
    "            df[f\"{inst}_vol_z20\"] = (\n",
    "                (log_vol - log_vol.rolling(20).mean())\n",
    "                / (log_vol.rolling(20).std() + 1e-12)\n",
    "            )\n",
    "            df[f\"{inst}_vol_chg5\"] = log_vol.diff(5)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = add_periodic_date_features(df)\n",
    "df = add_instrument_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constants",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUMENTS = [f\"INSTRUMENT_{i}\" for i in range(1, 11)]\n",
    "DATE_FEATURES = [\n",
    "    \"dow_sin\", \"dow_cos\",\n",
    "    \"doy_sin\", \"doy_cos\",\n",
    "    \"month_sin\", \"month_cos\",\n",
    "    \"woy_sin\", \"woy_cos\",\n",
    "]\n",
    "MACRO_FEATURES = [\n",
    "    c for c in [\n",
    "        \"1mo\", \"1.5month\", \"2mo\", \"3mo\", \"4mo\", \"6mo\",\n",
    "        \"1yr\", \"2yr\", \"3yr\", \"5yr\", \"7yr\", \"10yr\", \"20yr\", \"30yr\",\n",
    "    ]\n",
    "    if c in df.columns and df[c].notna().mean() > 0.5\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray):\n",
    "    x = x - np.max(x)\n",
    "    e = np.exp(x)\n",
    "    return e / (e.sum() + 1e-12)\n",
    "\n",
    "def cap_and_renorm(w: pd.Series, cap=0.25) -> pd.Series:\n",
    "    w = w.clip(lower=0.0, upper=cap)\n",
    "    s = float(w.sum())\n",
    "    if s <= 0:\n",
    "        return pd.Series(1.0 / len(w), index=w.index)\n",
    "    return w / s\n",
    "\n",
    "def build_feature_cols(df: pd.DataFrame, inst: str):\n",
    "    own_cols = [\n",
    "        col for col in df.columns\n",
    "        if col == inst or col.startswith(f\"{inst}_\")\n",
    "    ]\n",
    "    cols = DATE_FEATURES + MACRO_FEATURES + own_cols\n",
    "    return [col for col in cols if col in df.columns]\n",
    "\n",
    "def make_labels_next_return(df: pd.DataFrame, inst: str):\n",
    "    x = df[inst].astype(float)\n",
    "    return x.shift(-1) / x - 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_scores(\n",
    "    df: pd.DataFrame,\n",
    "    min_train: int = 750,\n",
    "    val_size: int = 252,\n",
    "):\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [150, 300],\n",
    "        \"max_depth\": [3, 4],\n",
    "        \"learning_rate\": [0.03, 0.05],\n",
    "        \"subsample\": [0.8],\n",
    "        \"colsample_bytree\": [0.8],\n",
    "        \"reg_lambda\": [1.0, 3.0],\n",
    "    }\n",
    "\n",
    "    preds = {}\n",
    "    validation_rows = []\n",
    "    fitted_models = {}\n",
    "\n",
    "    for inst in INSTRUMENTS:\n",
    "        feat_cols = build_feature_cols(df, inst)\n",
    "        X_all = df.iloc[:-1][feat_cols].copy()\n",
    "        y_all = make_labels_next_return(df, inst).iloc[:-1]\n",
    "\n",
    "        mask = ~y_all.isna()\n",
    "        X = X_all.loc[mask]\n",
    "        y = y_all.loc[mask]\n",
    "\n",
    "        if len(X) < min_train + val_size:\n",
    "            preds[inst] = 0.0\n",
    "            validation_rows.append(\n",
    "                {\n",
    "                    \"instrument\": inst,\n",
    "                    \"n_features\": len(feat_cols),\n",
    "                    \"n_train\": 0,\n",
    "                    \"n_val\": 0,\n",
    "                    \"best_params\": None,\n",
    "                    \"val_rmse\": np.nan,\n",
    "                    \"val_corr\": np.nan,\n",
    "                    \"val_hit_rate\": np.nan,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        X_train = X.iloc[:-val_size]\n",
    "        y_train = y.iloc[:-val_size]\n",
    "        X_val = X.iloc[-val_size:]\n",
    "        y_val = y.iloc[-val_size:]\n",
    "\n",
    "        best_params = None\n",
    "        best_score = -np.inf\n",
    "\n",
    "        for params in ParameterGrid(param_grid):\n",
    "            model = XGBRegressor(\n",
    "                objective=\"reg:squarederror\",\n",
    "                tree_method=\"hist\",\n",
    "                random_state=0,\n",
    "                n_jobs=1,\n",
    "                **params,\n",
    "            )\n",
    "            model.fit(X_train.values, y_train.values)\n",
    "\n",
    "            val_pred = model.predict(X_val.values)\n",
    "            val_corr = pd.Series(val_pred).corr(pd.Series(y_val.values))\n",
    "            val_corr = 0.0 if pd.isna(val_corr) else float(val_corr)\n",
    "\n",
    "            if val_corr > best_score:\n",
    "                best_score = val_corr\n",
    "                best_params = params\n",
    "\n",
    "        final_model = XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=0,\n",
    "            n_jobs=1,\n",
    "            **best_params,\n",
    "        )\n",
    "        final_model.fit(X.values, y.values)\n",
    "\n",
    "        val_pred = final_model.predict(X_val.values)\n",
    "        val_rmse = float(np.sqrt(np.mean((val_pred - y_val.values) ** 2)))\n",
    "        val_corr = pd.Series(val_pred).corr(pd.Series(y_val.values))\n",
    "        val_corr = 0.0 if pd.isna(val_corr) else float(val_corr)\n",
    "        val_hit_rate = float(((val_pred > 0) == (y_val.values > 0)).mean())\n",
    "\n",
    "        validation_rows.append(\n",
    "            {\n",
    "                \"instrument\": inst,\n",
    "                \"n_features\": len(feat_cols),\n",
    "                \"n_train\": len(X_train),\n",
    "                \"n_val\": len(X_val),\n",
    "                \"best_params\": best_params,\n",
    "                \"val_rmse\": val_rmse,\n",
    "                \"val_corr\": val_corr,\n",
    "                \"val_hit_rate\": val_hit_rate,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        x_last = df.loc[df.index[-1], feat_cols].astype(float)\n",
    "        preds[inst] = float(final_model.predict([x_last.values])[0])\n",
    "        fitted_models[inst] = final_model\n",
    "\n",
    "    validation_df = pd.DataFrame(validation_rows).sort_values(\"val_corr\", ascending=False)\n",
    "\n",
    "    print(\"Validation results by instrument:\")\n",
    "    display(\n",
    "        validation_df[\n",
    "            [\n",
    "                \"instrument\",\n",
    "                \"n_features\",\n",
    "                \"n_train\",\n",
    "                \"n_val\",\n",
    "                \"val_rmse\",\n",
    "                \"val_corr\",\n",
    "                \"val_hit_rate\",\n",
    "                \"best_params\",\n",
    "            ]\n",
    "        ].round(4)\n",
    "    )\n",
    "\n",
    "    print(\"\\nAverage validation metrics:\")\n",
    "    display(\n",
    "        validation_df[[\"val_rmse\", \"val_corr\", \"val_hit_rate\"]]\n",
    "        .mean()\n",
    "        .to_frame(\"mean\")\n",
    "        .T.round(4)\n",
    "    )\n",
    "\n",
    "    return fitted_models, pd.Series(preds), validation_df\n",
    "\n",
    "models, pred, validation_df = train_predict_scores(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weights",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_weights(\n",
    "    pred: pd.Series,\n",
    "    beta=5.0,\n",
    "    cap=0.25,\n",
    "    smooth_alpha=0.35,\n",
    "    prev_weights: pd.Series | None = None,\n",
    "):\n",
    "    scores = pred.copy()\n",
    "\n",
    "    w = pd.Series(softmax(beta * scores.values), index=INSTRUMENTS)\n",
    "    w = cap_and_renorm(w, cap=cap)\n",
    "\n",
    "    if prev_weights is not None:\n",
    "        prev_weights = prev_weights.reindex(INSTRUMENTS).fillna(0.0)\n",
    "        prev_weights = prev_weights / prev_weights.sum()\n",
    "        w = smooth_alpha * w + (1.0 - smooth_alpha) * prev_weights\n",
    "        w = cap_and_renorm(w, cap=cap)\n",
    "\n",
    "    return w\n",
    "\n",
    "def write_submission(weights: pd.Series, team_name: str, round_n: int, out_path=\".\"):\n",
    "    out = pd.DataFrame({\"asset\": weights.index, \"weight\": weights.values})\n",
    "    fname = f\"{team_name}_round_{round_n}.csv\"\n",
    "    out.to_csv(f\"{out_path}/{fname}\", index=False)\n",
    "    return fname\n",
    "\n",
    "prev = None\n",
    "w = construct_weights(pred, prev_weights=prev)\n",
    "fname = write_submission(w, team_name=\"HiddenLabel\", round_n=1, out_path=\".\")\n",
    "print(\"Wrote:\", fname)\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backtest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_best_model_for_instrument(\n",
    "    df: pd.DataFrame,\n",
    "    inst: str,\n",
    "    end_idx: int,\n",
    "    min_train: int = 750,\n",
    "    val_size: int = 252,\n",
    "):\n",
    "    feat_cols = build_feature_cols(df, inst)\n",
    "    X_all = df.iloc[:end_idx][feat_cols].copy()\n",
    "    y_all = make_labels_next_return(df, inst).iloc[:end_idx]\n",
    "\n",
    "    mask = ~y_all.isna()\n",
    "    X = X_all.loc[mask]\n",
    "    y = y_all.loc[mask]\n",
    "\n",
    "    if len(X) < min_train + val_size:\n",
    "        return None\n",
    "\n",
    "    X_train = X.iloc[:-val_size]\n",
    "    y_train = y.iloc[:-val_size]\n",
    "    X_val = X.iloc[-val_size:]\n",
    "    y_val = y.iloc[-val_size:]\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [150, 300],\n",
    "        \"max_depth\": [3, 4],\n",
    "        \"learning_rate\": [0.03, 0.05],\n",
    "        \"subsample\": [0.8],\n",
    "        \"colsample_bytree\": [0.8],\n",
    "        \"reg_lambda\": [1.0, 3.0],\n",
    "    }\n",
    "\n",
    "    best_params = None\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        model = XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=0,\n",
    "            n_jobs=1,\n",
    "            **params,\n",
    "        )\n",
    "        model.fit(X_train.values, y_train.values)\n",
    "        val_pred = model.predict(X_val.values)\n",
    "        val_corr = pd.Series(val_pred).corr(pd.Series(y_val.values))\n",
    "        val_corr = 0.0 if pd.isna(val_corr) else float(val_corr)\n",
    "\n",
    "        if val_corr > best_score:\n",
    "            best_score = val_corr\n",
    "            best_params = params\n",
    "\n",
    "    if best_params is None:\n",
    "        return None\n",
    "\n",
    "    final_model = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=0,\n",
    "        n_jobs=1,\n",
    "        **best_params,\n",
    "    )\n",
    "    final_model.fit(X.values, y.values)\n",
    "\n",
    "    return {\n",
    "        \"model\": final_model,\n",
    "        \"feature_cols\": feat_cols,\n",
    "        \"best_params\": best_params,\n",
    "        \"val_corr\": best_score,\n",
    "    }\n",
    "\n",
    "def backtest_model(\n",
    "    df: pd.DataFrame,\n",
    "    start_idx: int = 1500,\n",
    "    retrain_every: int = 63,\n",
    "    beta: float = 5.0,\n",
    "    filter_bad_instruments: bool = True,\n",
    "):\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    next_returns = pd.DataFrame({inst: make_labels_next_return(df, inst) for inst in INSTRUMENTS})\n",
    "\n",
    "    pred_rows = []\n",
    "    selected_rows = []\n",
    "\n",
    "    for t in range(start_idx, len(df) - 1, retrain_every):\n",
    "        row = {\"date\": df.loc[t, \"date\"]}\n",
    "        selected = []\n",
    "\n",
    "        for inst in INSTRUMENTS:\n",
    "            fitted = fit_best_model_for_instrument(df, inst, end_idx=t)\n",
    "            if fitted is None:\n",
    "                row[inst] = np.nan\n",
    "                continue\n",
    "\n",
    "            x_test = df.loc[t, fitted[\"feature_cols\"]].astype(float)\n",
    "            row[inst] = float(fitted[\"model\"].predict([x_test.values])[0])\n",
    "\n",
    "            if (not filter_bad_instruments) or (fitted[\"val_corr\"] > 0):\n",
    "                selected.append(inst)\n",
    "\n",
    "        pred_rows.append(row)\n",
    "        selected_rows.append({\"date\": df.loc[t, \"date\"], \"selected\": selected})\n",
    "\n",
    "    pred_df = pd.DataFrame(pred_rows)\n",
    "    selected_df = pd.DataFrame(selected_rows)\n",
    "\n",
    "    actual_df = next_returns.iloc[start_idx:len(df) - 1:retrain_every].reset_index(drop=True)\n",
    "    actual_df.insert(\n",
    "        0,\n",
    "        \"date\",\n",
    "        df[\"date\"].iloc[start_idx:len(df) - 1:retrain_every].reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "    pred_mat = pred_df[INSTRUMENTS].copy()\n",
    "    act_mat = actual_df[INSTRUMENTS].copy()\n",
    "\n",
    "    if filter_bad_instruments:\n",
    "        for i, selected in enumerate(selected_df[\"selected\"]):\n",
    "            excluded = [inst for inst in INSTRUMENTS if inst not in selected]\n",
    "            pred_mat.loc[i, excluded] = np.nan\n",
    "\n",
    "    ic_by_date = pred_mat.corrwith(act_mat, axis=1, method=\"spearman\")\n",
    "    directional_accuracy = ((pred_mat.values > 0) == (act_mat.values > 0)).mean()\n",
    "\n",
    "    pred_values = pred_mat.to_numpy(dtype=float)\n",
    "    pred_values = np.where(np.isnan(pred_values), -np.inf, pred_values)\n",
    "    pred_values = pred_values - np.max(pred_values, axis=1, keepdims=True)\n",
    "    exp_scores = np.exp(beta * pred_values)\n",
    "    exp_scores[np.isinf(pred_values)] = 0.0\n",
    "    weights = exp_scores / (exp_scores.sum(axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "    portfolio_returns = (weights * act_mat.to_numpy()).sum(axis=1)\n",
    "    equal_weight_returns = act_mat.mean(axis=1).to_numpy()\n",
    "\n",
    "    top3_mask = pred_mat.rank(axis=1, ascending=False, method=\"first\") <= 3\n",
    "    top3_weights = top3_mask.div(top3_mask.sum(axis=1), axis=0).fillna(0.0).to_numpy()\n",
    "    top3_returns = (top3_weights * act_mat.to_numpy()).sum(axis=1)\n",
    "\n",
    "    equity_curve = pd.Series((1 + portfolio_returns).cumprod(), index=pred_df[\"date\"])\n",
    "    ann_factor = np.sqrt(252 / retrain_every)\n",
    "\n",
    "    strategy_curve = pd.Series((1 + portfolio_returns).cumprod())\n",
    "    equal_weight_curve = pd.Series((1 + equal_weight_returns).cumprod())\n",
    "    top3_curve = pd.Series((1 + top3_returns).cumprod())\n",
    "\n",
    "    metrics = pd.DataFrame(\n",
    "        {\n",
    "            \"n_test_points\": [len(pred_df), len(pred_df), len(pred_df)],\n",
    "            \"mean_spearman_ic\": [ic_by_date.mean(), np.nan, np.nan],\n",
    "            \"hit_rate\": [directional_accuracy, np.nan, np.nan],\n",
    "            \"annualized_sharpe\": [\n",
    "                portfolio_returns.mean() / (portfolio_returns.std(ddof=1) + 1e-12) * ann_factor,\n",
    "                equal_weight_returns.mean() / (equal_weight_returns.std(ddof=1) + 1e-12) * ann_factor,\n",
    "                top3_returns.mean() / (top3_returns.std(ddof=1) + 1e-12) * ann_factor,\n",
    "            ],\n",
    "            \"avg_period_return\": [\n",
    "                portfolio_returns.mean(),\n",
    "                equal_weight_returns.mean(),\n",
    "                top3_returns.mean(),\n",
    "            ],\n",
    "            \"vol_period_return\": [\n",
    "                portfolio_returns.std(ddof=1),\n",
    "                equal_weight_returns.std(ddof=1),\n",
    "                top3_returns.std(ddof=1),\n",
    "            ],\n",
    "            \"total_return\": [\n",
    "                strategy_curve.iloc[-1] - 1.0,\n",
    "                equal_weight_curve.iloc[-1] - 1.0,\n",
    "                top3_curve.iloc[-1] - 1.0,\n",
    "            ],\n",
    "            \"max_drawdown\": [\n",
    "                (strategy_curve / strategy_curve.cummax() - 1.0).min(),\n",
    "                (equal_weight_curve / equal_weight_curve.cummax() - 1.0).min(),\n",
    "                (top3_curve / top3_curve.cummax() - 1.0).min(),\n",
    "            ],\n",
    "        },\n",
    "        index=[\"strategy\", \"equal_weight\", \"top3_predicted\"],\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"predictions\": pred_df,\n",
    "        \"actuals\": actual_df,\n",
    "        \"selected\": selected_df,\n",
    "        \"ic_by_date\": ic_by_date,\n",
    "        \"portfolio_returns\": pd.Series(portfolio_returns, index=pred_df[\"date\"]),\n",
    "        \"equity_curve\": equity_curve,\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "\n",
    "bt = backtest_model(df, start_idx=1500, retrain_every=63, beta=5.0, filter_bad_instruments=True)\n",
    "display(bt[\"metrics\"].round(4))\n",
    "bt[\"equity_curve\"].plot(title=\"Out-of-Sample Equity Curve\", figsize=(10, 4))\n",
    "print(\"Selected instruments on last rebalance:\", bt[\"selected\"].iloc[-1][\"selected\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
